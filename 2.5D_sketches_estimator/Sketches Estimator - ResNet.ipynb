{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MnbORtVLnUC1"},"outputs":[],"source":["import os, sys\n","project_path = '/content/gdrive/MyDrive/master/2.5D_sketches_estimator'\n","sys.path.append(project_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13862,"status":"ok","timestamp":1660355770114,"user":{"displayName":"baba yu","userId":"15024822712768977594"},"user_tz":-60},"id":"QID1VU6cUbn4","outputId":"51ea9741-11e9-4a56-c1b2-cc9be96c7623"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1660355770114,"user":{"displayName":"baba yu","userId":"15024822712768977594"},"user_tz":-60},"id":"GQK6o2aSJn_Y","outputId":"ee4a65af-0936-4f80-89a6-2b4308b347b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/master/2.5D_sketches_estimator\n"]}],"source":["%cd {project_path}"]},{"cell_type":"markdown","metadata":{"id":"VINLKlu3ZTMW"},"source":["# Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"sgCMJXwxZC2s","executionInfo":{"status":"ok","timestamp":1660424575616,"user_tz":-60,"elapsed":4423,"user":{"displayName":"baba yu","userId":"15024822712768977594"}}},"outputs":[],"source":["# import DL modules\n","import tensorflow as tf\n","import keras as keras\n","from keras.models import Sequential, Model\n","from keras import layers\n","# from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout, \\\n","#               Conv3D, MaxPooling3D, Input, Deconv3D, BatchNormalization, \\\n","#               Activation, Reshape\n","from keras import optimizers\n","\n","# import service modules\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1660355774433,"user":{"displayName":"baba yu","userId":"15024822712768977594"},"user_tz":-60},"id":"iY6uGg8EB-CP","outputId":"2f5b7427-7edc-44b3-e763-97c48cca54d7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}],"source":["tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjQ5AmAdZasD"},"outputs":[],"source":["#@title Setup\n","# network and training parameters\n","RANDOM_SEED = 10\n","SAMPLE_RATE = 0.01 #@param\n","N_EPOCH = 1 #@param {type: \"integer\"}\n","BATCH_SIZE = 128 #@param {type: \"integer\"}\n","VERBOSE = 1 #@param {type: \"boolean\"}\n","# LOSS_FUNCTION = 'MeanSquaredError'\n","LOSS_FUNCTION = 'SSIM'\n","VALIDATION_SPLIT = 0.2 #@param\n","TEST_SPLIT = 0.1 #@param\n","INPUT_SHAPE = (256, 256, 256, 3) #@param\n","HEIGHT = INPUT_SHAPE[1]\n","WIDTH = INPUT_SHAPE[2]\n","LR = 0.0002\n","OPTIMIZER = tf.optimizers.Adam(\n","  learning_rate=LR,\n","  amsgrad=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rc6E-NRrZF6f"},"outputs":[],"source":["# fix seed\n","np.random.seed(RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{"id":"oR-k22xtcIA4"},"source":["# Load Pre-processed Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnGb1YczoGWk"},"outputs":[],"source":["# reference: https://keras.io/examples/vision/depth_estimation/\n","class DataLoader(tf.keras.utils.Sequence):\n","  def __init__(self, data, batch_size=6, dim=(256, 256), n_channels=3, shuffle=True):\n","    \"\"\"\n","    Initialization\n","    \"\"\"\n","    self.data = data\n","    self.indices = self.data.index.tolist()\n","    self.dim = dim\n","    self.n_channels = n_channels\n","    self.batch_size = batch_size\n","    self.shuffle = shuffle\n","    self.min_depth = 0.1\n","    self.on_epoch_end()\n","\n","  def __len__(self):\n","    return int(np.ceil(len(self.data) / self.batch_size))\n","\n","  def __getitem__(self, index):\n","    # modify batch size of last batch\n","    if (index + 1) * self.batch_size > len(self.indices):\n","      self.batch_size = len(self.indices) - index * self.batch_size\n","    # Generate one batch of data\n","    # Generate indices of the batch\n","    index = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n","    # Find list of IDs\n","    batch = [self.indices[k] for k in index]\n","    x, y = self.load_batch(batch)\n","    return x, y\n","\n","\n","  def on_epoch_end(self):\n","    \"\"\"\n","    Updates indexes after each epoch\n","    \"\"\"\n","    self.index = np.arange(len(self.indices))\n","    if self.shuffle == True:\n","      np.random.shuffle(self.index)\n","\n","  def load(self, image_path, sketch_path):\n","    \"\"\"\n","    Load image and 2.5D sketch pair.\n","    \"\"\"\n","    img = np.float32(cv2.imread(image_path))\n","    sketch = np.float32(cv2.imread(sketch_path))\n","    # img = cv2.imread(image_path)\n","    # sketch = cv2.imread(sketch_path)\n","    return img, sketch\n","\n","  def load_batch(self, batch):\n","    \"\"\"\n","    Load one batch of data.\n","    \"\"\"\n","    x = np.empty((self.batch_size, *self.dim, self.n_channels), dtype='float32')\n","    y = np.empty((self.batch_size, *self.dim, self.n_channels), dtype='float32')\n","\n","    for i, batch_id in enumerate(batch):\n","      x[i,], y[i,] = self.load(\n","        self.data[\"raw_image_file_paths\"][batch_id],\n","        self.data[\"normal_masked_paths\"][batch_id],\n","      )\n","    return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTALoWRWcDhT"},"outputs":[],"source":["index_df = pd.read_csv(os.getcwd()+'/data_paths_optimal.csv')\n","index_df = index_df.sample(frac=SAMPLE_RATE, random_state=RANDOM_SEED, ignore_index=True)\n","num_instances = len(index_df.index)\n","validation_boundary = int(num_instances*VALIDATION_SPLIT)\n","test_boundary = int(num_instances*TEST_SPLIT) + validation_boundary\n","\n","# create data loaders\n","train_loader = DataLoader(data=index_df[test_boundary:].reset_index(drop='true'), batch_size=BATCH_SIZE, dim=INPUT_SHAPE[1:3], n_channels=INPUT_SHAPE[3], shuffle=False)\n","test_loader = DataLoader(data=index_df[validation_boundary:test_boundary].reset_index(drop='true'), batch_size=BATCH_SIZE, dim=INPUT_SHAPE[1:3], n_channels=INPUT_SHAPE[3], shuffle=False)\n","validation_loader = DataLoader(data=index_df[:validation_boundary].reset_index(drop='true'), batch_size=BATCH_SIZE, dim=INPUT_SHAPE[1:3], n_channels=INPUT_SHAPE[3], shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1660355775556,"user":{"displayName":"baba yu","userId":"15024822712768977594"},"user_tz":-60},"id":"e5k8JPU1Cq90","outputId":"39505d3d-ee19-479a-a4d3-be16321e5b18"},"outputs":[{"output_type":"stream","name":"stdout","text":["949\n","271\n","135\n"]}],"source":["print(len(train_loader.index))\n","print(len(validation_loader.index))\n","print(len(test_loader.index))"]},{"cell_type":"markdown","metadata":{"id":"E3n0o48NcNOu"},"source":["# Define Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7T_Goq9I4Wz"},"outputs":[],"source":["# reference: https://towardsdev.com/implement-resnet-with-tensorflow2-4ee81e33a1ac\n","class ResBlock(keras.Model):\n","  def __init__(self, filters, downsample):\n","    super().__init__()\n","    if downsample:\n","      self.conv1 = layers.Conv2D(filters, 3, 2, padding='same')\n","      self.shortcut = keras.Sequential([\n","        layers.Conv2D(filters, 1, 2),\n","        layers.BatchNormalization()\n","      ])\n","    else:\n","      self.conv1 = layers.Conv2D(filters, 3, 1, padding='same')\n","      self.shortcut = keras.Sequential()\n","\n","    self.bn1 = layers.BatchNormalization()\n","    self.rl1 = layers.LeakyReLU(alpha=0.2)\n","    self.bn2 = layers.BatchNormalization()\n","    self.rl2 = layers.LeakyReLU(alpha=0.2)\n","    self.rl3 = layers.LeakyReLU(alpha=0.2)\n","\n","    self.conv2 = layers.Conv2D(filters, 3, 1, padding='same')\n","  def call(self, input):\n","    shortcut = self.shortcut(input)\n","\n","    input = self.conv1(input)\n","    input = self.bn1(input)\n","    input = self.rl1(input)\n","\n","    input = self.conv2(input)\n","    input = self.bn2(input)\n","    input = self.rl2(input)\n","\n","    input = input + shortcut\n","    return self.rl3(input)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FgIO1crcMgX"},"outputs":[],"source":["# encoder - ResNet18\n","class encoder(keras.Model):\n","  def __init__(self, output_shape=256, *args, **kwargs):\n","    super().__init__(*args, **kwargs)\n","\n","    self.layer0 = keras.Sequential([\n","      layers.Conv2D(filters=64, kernel_size=7, strides=2, padding='same'),\n","      layers.MaxPool2D(pool_size=3, strides=2, padding='same'),\n","      layers.BatchNormalization(),\n","      layers.ReLU()\n","    ], name='layer0')\n","    \n","    self.layer1 = keras.Sequential([\n","      ResBlock(64, downsample=False),\n","      ResBlock(64, downsample=False)\n","    ], name='layer1')\n","\n","    self.layer2 = keras.Sequential([\n","      ResBlock(128, downsample=True),\n","      ResBlock(128, downsample=False)\n","    ], name='layer2')\n","\n","    self.layer3 = keras.Sequential([\n","      ResBlock(256, downsample=True),\n","      ResBlock(256, downsample=False)\n","    ], name='layer3')\n","\n","    # self.layer4 = keras.Sequential([\n","    #   ResBlock(512, downsample=True),\n","    #   ResBlock(512, downsample=False)\n","    # ], name='layer4')\n","\n","    # self.gap = layers.GlobalAveragePooling2D(name='gap')\n","    # self.fc_output = layers.Dense(output_shape, activation='softmax', name='dense_output')\n","\n","  def call(self, input):\n","    input = self.layer0(input)\n","    input = self.layer1(input)\n","    input = self.layer2(input)\n","    input = self.layer3(input)\n","    # input = self.layer4(input)\n","    # input = self.gap(input)\n","    # input = self.fc_output(input)\n","    # input = tf.keras.activations.tanh(input)\n","    # input = tf.keras.activations.relu(tf.math.sign(input))\n","    print(input)\n","\n","    return input"]},{"cell_type":"code","source":["input = tf.constant([-1, -0.6, -0.4, 0, 0.4, 0.6, 1], dtype = tf.float32)\n","input = tf.keras.activations.tanh(input-0.5)\n","input = tf.keras.activations.relu(tf.math.sign(input))"],"metadata":{"id":"fW3fDnu-7a8F","executionInfo":{"status":"ok","timestamp":1660424597719,"user_tz":-60,"elapsed":357,"user":{"displayName":"baba yu","userId":"15024822712768977594"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvuQVxva7i4t","executionInfo":{"status":"ok","timestamp":1660424601305,"user_tz":-60,"elapsed":5,"user":{"displayName":"baba yu","userId":"15024822712768977594"}},"outputId":"98038771-74fe-4145-d2fa-ce6be9a3a8ef"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(7,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 1., 1.], dtype=float32)>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":797,"status":"ok","timestamp":1660355776351,"user":{"displayName":"baba yu","userId":"15024822712768977594"},"user_tz":-60},"id":"hyLrBZcKPsby","outputId":"c79009e3-7f50-4143-e254-7cc01ca8e740"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"Relu:0\", shape=(None, 16, 16, 256), dtype=float32)\n","Model: \"encoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," layer0 (Sequential)         (None, 64, 64, 64)        9728      \n","                                                                 \n"," layer1 (Sequential)         (None, 64, 64, 64)        148736    \n","                                                                 \n"," layer2 (Sequential)         (None, 32, 32, 128)       527488    \n","                                                                 \n"," layer3 (Sequential)         (None, 16, 16, 256)       2103552   \n","                                                                 \n","=================================================================\n","Total params: 2,789,504\n","Trainable params: 2,785,024\n","Non-trainable params: 4,480\n","_________________________________________________________________\n"]}],"source":["# # Build Model\n","# # initialize model\n","encoder_model=encoder()\n","# encoder_model.build(input_shape=INPUT_SHAPE)\n","encoder_model.build(input_shape=(None, 256, 256, 3))\n","\n","# summary model\n","# encoder_model.call(layers.Input((256, 256, 3)))\n","encoder_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Wrmmxpzmn88"},"outputs":[],"source":["# decode block\n","class DecodeBlock(keras.Model):\n","  def __init__(self, name, filters, kernel_size=3, strides=2):\n","    super().__init__()\n","\n","    self._name = name\n","    \n","    self.deconv1 = layers.Conv2DTranspose(filters=filters, kernel_size=3, strides=strides, padding='same')\n","    self.bn1 = layers.BatchNormalization()\n","    self.rl1 = layers.LeakyReLU(alpha=0.2)\n","\n","    \n","\n","  def call(self, input):\n","    input = self.deconv1(input)\n","    input = self.bn1(input)\n","    input = self.rl1(input)\n","\n","\n","\n","    return input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGG7fNRSAsSW"},"outputs":[],"source":["# decoder\n","class decoder(keras.Model):\n","  def __init__(self, *args, **kwargs):\n","    super().__init__(*args, **kwargs)\n","\n","    self.layer0 = DecodeBlock(name='layer0', filters=128)\n","\n","    self.layer1 = DecodeBlock(name='layer1', filters=64)\n","\n","    self.layer2 = DecodeBlock(name='layer2', filters=32)\n","\n","    self.layer3 = DecodeBlock(name='layer3', filters=3)\n","\n","    # self.layer4 = DecodeBlock(3, name='layer4')\n","\n","\n","  def call(self, input):\n","    input = self.layer0(input)\n","    input = self.layer1(input)\n","    input = self.layer2(input)\n","    input = self.layer3(input)\n","    # input = self.layer4(input)\n","\n","    return input"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":483,"status":"ok","timestamp":1660355776832,"user":{"displayName":"baba yu","userId":"15024822712768977594"},"user_tz":-60},"id":"w6-HUT_lXioW","outputId":"641ee170-ae42-403d-f1bd-bdadf1a8e066"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," layer0 (DecodeBlock)        (None, 32, 32, 128)       295552    \n","                                                                 \n"," layer1 (DecodeBlock)        (None, 64, 64, 64)        74048     \n","                                                                 \n"," layer2 (DecodeBlock)        (None, 128, 128, 32)      18592     \n","                                                                 \n"," layer3 (DecodeBlock)        (None, 256, 256, 3)       879       \n","                                                                 \n","=================================================================\n","Total params: 389,071\n","Trainable params: 388,617\n","Non-trainable params: 454\n","_________________________________________________________________\n"]}],"source":["# Build Model\n","# initialize model\n","decoder_model=decoder()\n","decoder_model.build(input_shape=(400, 16, 16, 256))\n","\n","# summary model\n","decoder_model.call(layers.Input((16, 16, 256)))\n","decoder_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"joFEOHT7sbsm"},"outputs":[],"source":["# customized loss\n","def ssim_loss(target, pred):\n","  # edges\n","  dy_true, dx_true = tf.image.image_gradients(target)\n","  dy_pred, dx_pred = tf.image.image_gradients(pred)\n","  weights_x = tf.exp(tf.reduce_mean(tf.abs(dx_true)))\n","  weights_y = tf.exp(tf.reduce_mean(tf.abs(dy_true)))\n","\n","  # smoothness\n","  smoothness_x = dx_pred * weights_x\n","  smoothness_y = dy_pred * weights_y\n","  smoothness_loss = tf.reduce_mean(abs(smoothness_x)) + tf.reduce_mean(abs(smoothness_y))\n","\n","  # Structural similarity (SSIM) index\n","  loss = tf.reduce_mean(\n","    1 - tf.image.ssim(\n","      target, pred, max_val=WIDTH, filter_size=7, k1=0.01 ** 2, k2=0.03 ** 2\n","    )\n","  )\n","\n","  return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRjt3RmHXhHO"},"outputs":[],"source":["# encoder-decoder\n","model = Sequential()\n","encoder_model = encoder()\n","model.add(encoder_model)\n","decoder_model = decoder()\n","model.add(decoder_model)\n","\n","if LOSS_FUNCTION == 'SSIM':\n","  model.compile(loss=ssim_loss, optimizer=OPTIMIZER, metrics=['accuracy'])\n","else:\n","  model.compile(loss=LOSS_FUNCTION, optimizer=OPTIMIZER, metrics=['accuracy'])\n"]},{"cell_type":"markdown","metadata":{"id":"ZPJkxpNq1ZEF"},"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZUNhbVDFy_jg"},"outputs":[],"source":["# checkpoints\n","# additional checkpoint load code and temp directory definition\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","\n","checkpoint_path = project_path+\"/intermediate/weights{epoch:02d}.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# definition of checkpoint parameters file\n","checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=False, save_freq='epoch')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UbwCA9R0z7Yq","executionInfo":{"status":"error","timestamp":1660355806421,"user_tz":-60,"elapsed":29592,"user":{"displayName":"baba yu","userId":"15024822712768977594"}},"outputId":"972a1084-6d3b-4d4c-8215-0a9bcc99612d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"encoder_1/Relu:0\", shape=(128, 16, 16, 256), dtype=float32)\n","tf.Tensor(\n","[[[[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  ...\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]]\n","\n","\n"," [[[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  ...\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]]\n","\n","\n"," [[[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  ...\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]]\n","\n","\n"," ...\n","\n","\n"," [[[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  ...\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]]\n","\n","\n"," [[[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  ...\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]]\n","\n","\n"," [[[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  ...\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]\n","\n","  [[0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   ...\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]\n","   [0. 0. 0. ... 0. 0. 0.]]]], shape=(128, 16, 16, 256), dtype=float32)\n","Tensor(\"encoder_1/Relu:0\", shape=(None, None, None, 256), dtype=float32)\n","Tensor(\"sequential_6/encoder_1/Relu:0\", shape=(None, None, None, 256), dtype=float32)\n","Tensor(\"sequential_6/encoder_1/Relu:0\", shape=(None, None, None, 256), dtype=float32)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-049453963ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# train\n","history = model.fit(train_loader, batch_size=BATCH_SIZE, epochs=N_EPOCH, verbose=VERBOSE, validation_data=validation_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8fJ9d-Wf0Q_6"},"outputs":[],"source":["# continue train\n","new_model = load_model(project_path+\"/intermediate/weights%02d.ckpt\" % history.params['epochs'])\n","remain_n_epoch = N_EPOCH - history.params['epochs']\n","if remain_n_epoch == 0:\n","  print(\"Train finished.\")\n","else:\n","  new_history = new_model.fit(train_loader, batch_size=BATCH_SIZE, epochs=remain_n_epoch, verbose=VERBOSE, validation_data=validation_loader, callbacks=[checkpoint])"]},{"cell_type":"markdown","metadata":{"id":"nA_WXUJU0uoM"},"source":["# Demonstrate Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SmKI4zFy0YAp"},"outputs":[],"source":["# print test score\n","test_score = new_model.evaluate(test_loader, verbose=1)\n","print(\"\\nTest score/loss:\", test_score[0])\n","print('Test accuracy:', test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yreClthg0g_8"},"outputs":[],"source":["score = model.evaluate(test_loader, verbose=VERBOSE)\n","print(\"\\nTest score/loss:\", score[0])\n","print('Test accuracy:', score[1])\n","\n","# list all data in history\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.figure(figsize=(8,5))\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Accuracy History of Net')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.xticks(np.arange(0, N_EPOCH+1, 2.0))\n","plt.yticks(np.arange(0.6, 1.0, 0.1))\n","plt.ylim(0.6, 0.95)\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig(os.getcwd()+'/intermediate/acc_hist.png')\n","plt.show()\n","# summarize history for loss\n","plt.figure(figsize=(8,5))\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Loss History of Net')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.xticks(np.arange(0, N_EPOCH+1, 2.0))\n","plt.yticks(np.arange(0.6, 1.0, 0.1))\n","plt.ylim(0.6, 0.95)\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig(os.getcwd()+'/intermediate/acc_hist.png')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gRSkkJGY1Aib"},"source":["# Save Model Configures"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZ6TqmYo1CvB"},"outputs":[],"source":["# from keras.models import model_from_json\n","# model_json = model.to_json()\n","# open(project_path+'/intermediate/Net_architecture.json', 'w').write(model_json)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMMlxs67_RmA"},"outputs":[],"source":["# r1 = tf.random.uniform(shape=[256, 256, 3])\n","# r2 = tf.random.uniform(shape=[256, 256, 3])\n","# mse = tf.keras.losses.MeanSquaredError()\n","# mse(r1, r2).numpy()"]}],"metadata":{"colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"Sketches Estimator - ResNet.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNJZwxm6QrKCo/P6VpVsd/2"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}