{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"mM88fTNhi3CX"},"source":["# 3D Shape Estimator - Feasible Adam\n","A test run."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15167,"status":"ok","timestamp":1661662278565,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"TNZkrIqAiV-3","outputId":"060bcc30-14fc-4374-c61f-aced4f616264"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["import os, sys\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","project_path = '/content/gdrive/MyDrive/master/3d_shapes_estimator'\n","sys.path.append(project_path)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129511,"status":"ok","timestamp":1661662408069,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"W7lgIi9QN1Lp","outputId":"5df40bbe-8681-4c8f-bd67-886abd502f50"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Aug 28 04:51:17 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.8\n","  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n","\u001b[K     |████████████████████████████████| 668.3 MB 17 kB/s \n","\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.6)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.47.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.1.1)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.26.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n","Installing collected packages: tf-estimator-nightly, tensorflow\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n","Successfully installed tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be upgraded:\n","  libcudnn8\n","1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 3,139 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 7s (58.2 MB/s)\n","(Reading database ... 155676 files and directories currently installed.)\n","Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n","(Reading database ... 155654 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"]}],"source":["!nvidia-smi\n","!pip install tensorflow==2.8\n","!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1661662408070,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"rsoDigT5ijrU","outputId":"f14aa98c-43c9-4b7a-807b-6ae56fa07fea"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/master/3d_shapes_estimator\n"]}],"source":["%cd {project_path}"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4898,"status":"ok","timestamp":1661662412961,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"ow79qv6wcj-F"},"outputs":[],"source":["# import DL modules\n","import tensorflow as tf\n","import keras as keras\n","from keras.models import Sequential, Model\n","from keras import layers\n","from keras import optimizers\n","from keras.models import load_model\n","import keras.backend as K\n","\n","# import service modules\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import cv2\n","sys.path.append(os.getcwd()+'/utils')\n","import binvox_rw\n","import json"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1661662412962,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"oR_egn0l10Yt"},"outputs":[],"source":["#@title Setup\n","RUN_MODE = 'test'\n","OUTPUT_PATH = project_path+\"/intermediate/shape_estimator_normal_feasible_test_adam/\"\n","RANDOM_SEED = 10\n","IS_SAMPLE = False #@param\n","SAMPLE_RATE = 4\n","N_EPOCH = 25 #@param {type: \"integer\"}\n","BATCH_SIZE = 12 #@param {type: \"integer\"}\n","VERBOSE = 1 #@param {type: \"boolean\"}\n","GEN_LR = 0.00005\n","DISC_LR = 0.00005\n","OPTIMIZER = 'Adam'\n","GP_WEIGHT = 10.0\n","PREDICT_SKETCH = False\n","SHUFFLE = False\n","np.random.seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1661662412963,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"5ekIFAmrPAa4","outputId":"6e23c380-7d9c-46e9-9aef-80aa4d021323"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.8.0'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"96MHbWyp1uy5"},"source":["# Load Data"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1661662412963,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"4pUa3AUv1w8Y"},"outputs":[],"source":["# reference: https://keras.io/examples/vision/depth_estimation/\n","class DataLoader(tf.keras.utils.Sequence):\n","  def __init__(self, data, batch_size=15, shuffle=False):\n","    \"\"\"\n","    Initialization\n","    \"\"\"\n","    self.shuffle = shuffle\n","    self.data = data\n","    self.x1_file = self.data[0]\n","    self.x2_file = self.data[1]\n","    self.y_file = self.data[2]\n","    self.x0_file = self.data[3]\n","    self.indices = list(range(self.x1_file.len()))\n","    self.len_indices = len(self.indices)\n","    self.batch_size = batch_size\n","    self.on_epoch_end()\n","\n","  def __len__(self):\n","    if IS_SAMPLE == True:\n","      return int(np.ceil(self.len_indices / self.batch_size / SAMPLE_RATE))\n","    else:\n","      return int(np.ceil(self.len_indices / self.batch_size))\n","\n","  def __getitem__(self, index):\n","    # modify batch size of last batch\n","    batch_size = self.batch_size\n","    if (index + 1) * self.batch_size > len(self.indices):\n","      batch_size = len(self.indices) - index * self.batch_size\n","    # Generate one batch of data\n","    # Generate indices of the batch\n","    index = self.indices[index * batch_size : (index + 1) * batch_size]\n","    # Find list of IDs\n","    x1, x2, y, x0 = self.load_batch(index)\n","    return x1, x2, y, x0\n","\n","\n","  def on_epoch_end(self):\n","    \"\"\"\n","    Updates indexes after each epoch\n","    \"\"\"\n","    self.index = np.arange(len(self.indices))\n","    if self.shuffle == True:\n","        np.random.shuffle(self.index)\n","\n","  def load_batch(self, batch):\n","    \"\"\"\n","    Load one batch of data.\n","    \"\"\"\n","    x1 = self.x1_file[batch[0]:batch[-1]+1]\n","    x2 = self.x2_file[batch[0]:batch[-1]+1]\n","    y = (self.y_file[batch[0]:batch[-1]+1]).astype(np.float16)\n","    x0 = self.x0_file[batch[0]:batch[-1]+1]\n","    return x1, x2, y, x0"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1661662412964,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"alN5rp2sSVJQ"},"outputs":[],"source":["import h5py"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":702,"status":"ok","timestamp":1661662413656,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"GMQAVG7mSYfo"},"outputs":[],"source":["hdf5_path = '/content/gdrive/MyDrive/master/Data/half_data_shuffled.hdf5'\n","if PREDICT_SKETCH == True:\n","  train_dataset_file = (h5py.File(hdf5_path)['train_raw_image'], h5py.File(hdf5_path)['train_shape'])\n","  test_dataset_file = (h5py.File(hdf5_path)['test_raw_image'], h5py.File(hdf5_path)['test_shape'])\n","  validation_dataset_file = (h5py.File(hdf5_path)['validation_raw_image'], h5py.File(hdf5_path)['validation_shape'])\n","else:\n","  train_dataset_file = (h5py.File(hdf5_path)['train_normal'], h5py.File(hdf5_path)['train_depth'], h5py.File(hdf5_path)['train_shape'], h5py.File(hdf5_path)['train_raw_image'])\n","  test_dataset_file = (h5py.File(hdf5_path)['test_normal'], h5py.File(hdf5_path)['test_depth'], h5py.File(hdf5_path)['test_shape'], h5py.File(hdf5_path)['test_raw_image'])\n","  validation_dataset_file = (h5py.File(hdf5_path)['validation_normal'], h5py.File(hdf5_path)['validation_depth'], h5py.File(hdf5_path)['validation_shape'], h5py.File(hdf5_path)['validation_raw_image'])"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661662413657,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"NpWFt3C0S2F2"},"outputs":[],"source":["train_loader = DataLoader(data=train_dataset_file, batch_size=BATCH_SIZE, shuffle=False)\n","validation_loader = DataLoader(data=validation_dataset_file, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader = DataLoader(data=test_dataset_file, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1661662413657,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"XhwfRmfC9LS-","outputId":"7561fef2-4ce8-4288-ecbd-389c89beff83"},"outputs":[{"name":"stdout","output_type":"stream","text":["1434\n","180\n","180\n"]}],"source":["print(train_loader.__len__())\n","print(validation_loader.__len__())\n","print(test_loader.__len__())"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2951,"status":"ok","timestamp":1661662416604,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"h9H9Rue69V3K"},"outputs":[],"source":["sample = next(iter(train_loader))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1661662416951,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"fnrRPq8QHbCX","outputId":"a8ef964c-bb5c-40b3-b882-f2ee538f77a5"},"outputs":[{"data":{"text/plain":["(12, 256, 256, 3)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["sample[1].shape"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661662416952,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"vWRiqYOOzvBq"},"outputs":[],"source":["result = np.concatenate((sample[0], sample[1]), axis=3)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661662416952,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"COALqGSBz_Hm","outputId":"232b3478-e2e2-41e2-df79-a19bc18246a1"},"outputs":[{"data":{"text/plain":["(12, 256, 256, 6)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["result.shape"]},{"cell_type":"markdown","metadata":{"id":"ybE7yWmlcUZv"},"source":["# Define Model"]},{"cell_type":"markdown","metadata":{"id":"urxFoepJJ86Q"},"source":["## Generator"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661662416953,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"v7G9-QsHcSGS"},"outputs":[],"source":["# reference: https://towardsdev.com/implement-resnet-with-tensorflow2-4ee81e33a1ac\n","class ResBlock(layers.Layer):\n","  def __init__(self, filters, downsample):\n","    super().__init__()\n","    if downsample:\n","      self.conv1 = layers.Conv2D(filters, kernel_size=3, strides=2, padding='same', kernel_initializer = 'he_normal')\n","      self.shortcut = keras.Sequential([\n","        layers.Conv2D(filters, kernel_size=1, strides=2, kernel_initializer='he_normal'),\n","        layers.BatchNormalization()\n","      ])\n","    else:\n","      self.conv1 = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')\n","      self.shortcut = keras.Sequential()\n","\n","    self.bn1 = layers.BatchNormalization()\n","    self.rl1 = layers.LeakyReLU(alpha=0.2)\n","\n","    self.conv2 = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')\n","    self.bn2 = layers.BatchNormalization()\n","    self.rl2 = layers.LeakyReLU(alpha=0.2)\n","\n","    self.rl3 = layers.LeakyReLU(alpha=0.2)\n","  def call(self, inputs):\n","    shortcut = self.shortcut(inputs)\n","\n","    inputs = self.conv1(inputs)\n","    inputs = self.bn1(inputs)\n","    inputs = self.rl1(inputs)\n","\n","    inputs = self.conv2(inputs)\n","    inputs = self.bn2(inputs)\n","    inputs = self.rl2(inputs)\n","\n","    inputs = inputs + shortcut\n","    return self.rl3(inputs)\n","\n","class EncodeBlock(layers.Layer):\n","  def __init__(self, filters):\n","    super().__init__()\n","    # if downsample:\n","    #   self.conv1 = layers.Conv2D(filters, kernel_size=3, strides=2, padding='same', kernel_initializer = 'he_normal')\n","    #   self.shortcut = keras.Sequential([\n","    #     layers.Conv2D(filters, kernel_size=1, strides=2, kernel_initializer='he_normal'),\n","    #     layers.BatchNormalization()\n","    #   ])\n","    # else:\n","    #   self.conv1 = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')\n","    #   self.shortcut = keras.Sequential()\n","\n","    self.conv1 = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')\n","    self.bn1 = layers.BatchNormalization()\n","    self.rl1 = layers.ReLU()\n","\n","    self.conv2 = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')\n","    self.bn2 = layers.BatchNormalization()\n","    self.rl2 = layers.ReLU()\n","\n","    self.pool = layers.MaxPool2D(pool_size=(2, 2))\n","  def call(self, inputs):\n","    # shortcut = self.shortcut(inputs)\n","\n","    inputs = self.conv1(inputs)\n","    inputs = self.bn1(inputs)\n","    inputs = self.rl1(inputs)\n","\n","    inputs = self.conv2(inputs)\n","    inputs = self.bn2(inputs)\n","    inputs = self.rl2(inputs)\n","\n","    inputs = self.pool(inputs)\n","    # inputs = inputs + shortcut\n","    return inputs\n","\n","class BottleNeckBlock(layers.Layer):\n","  def __init__(self, dense_shape=400):\n","    super().__init__()\n","    self.pool = layers.AveragePooling2D(pool_size=4)\n","    self.flatten = layers.Flatten()\n","    self.rl1 = layers.LeakyReLU(alpha=0.2)\n","    self.fc1 = layers.Dense(dense_shape)\n","    self.rl2 = layers.LeakyReLU(alpha=0.2)\n","    self.fc2 = layers.Dense(16384)\n","    self.reshape = layers.Reshape((8, 8, 8, 32))\n","  def call(self, inputs):\n","    inputs = self.pool(inputs)\n","    inputs = self.flatten(inputs)\n","    inputs = self.fc1(inputs)\n","    inputs = self.rl1(inputs)\n","    inputs = self.fc2(inputs)\n","    inputs = self.rl2(inputs)\n","    inputs = self.reshape(inputs)\n","    return inputs\n","\n","class DecodeBlock(layers.Layer):\n","  def __init__(self, filters):\n","    super().__init__()\n","    self.deconv = layers.Conv3DTranspose(filters=filters, kernel_size=3, strides=2, padding='same', kernel_initializer = 'he_normal')\n","    self.bn1 = layers.BatchNormalization()\n","    self.rl1 = layers.ReLU()\n","\n","    self.conv = layers.Conv3D(filters=filters, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')\n","    self.bn2 = layers.BatchNormalization()\n","    self.rl2 = layers.ReLU()\n","  def call(self, inputs):\n","    inputs = self.deconv(inputs)\n","    inputs = self.bn1(inputs)\n","    inputs = self.rl1(inputs)\n","\n","    inputs = self.conv(inputs)\n","    inputs = self.bn2(inputs)\n","    inputs = self.rl2(inputs)\n","    return inputs"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1661662416953,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"_pOb1xwReZQu"},"outputs":[],"source":["class Generator(keras.Model):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.layer0 = keras.Sequential([\n","      layers.Conv2D(32, 7, 2, padding='same'),\n","      layers.MaxPool2D(pool_size=3, strides=2, padding='same'),\n","      layers.BatchNormalization(),\n","      layers.ReLU()\n","    ], name='layer0')\n","    \n","    self.layer1 = keras.Sequential([\n","      ResBlock(32, downsample=True),\n","      ResBlock(32, downsample=False)\n","    ], name='layer1')\n","\n","    self.layer2 = keras.Sequential([\n","      ResBlock(64, downsample=True),\n","      ResBlock(64, downsample=False)\n","    ], name='layer2')\n","\n","    self.layer3 = keras.Sequential([\n","      ResBlock(128, downsample=True),\n","      ResBlock(128, downsample=False)\n","    ], name='layer3')\n","\n","    # self.layer0 = EncodeBlock(16)\n","    # self.layer1 = EncodeBlock(32)\n","    # self.layer2 = EncodeBlock(64)\n","    # self.layer3 = EncodeBlock(128)\n","    # self.layer31 = EncodeBlock(128)\n","\n","    # bottleneck\n","    self.flatten = layers.Flatten()\n","    self.reshape = layers.Reshape((4, 4, 4, 128))\n","    # self.bottleneck = BottleNeckBlock()\n","\n","    self.layer4 = DecodeBlock(64)\n","    self.layer5 = DecodeBlock(32)\n","    self.layer6 = DecodeBlock(16)\n","    self.layer7 = DecodeBlock(8)\n","    self.layer8 = DecodeBlock(1)\n","\n","    # self.upsample = layers.UpSampling3D(size=(2, 2, 2))\n","\n","    # self.softmax = layers.Softmax()\n","\n","  def call(self, inputs):\n","\n","    inputs = self.layer0(inputs)\n","    inputs = self.layer1(inputs)\n","    inputs = self.layer2(inputs)\n","    inputs = self.layer3(inputs)\n","    # inputs = self.layer31(inputs)\n","\n","    inputs = self.flatten(inputs)\n","    inputs = self.reshape(inputs)\n","    # inputs = self.bottleneck(inputs)\n","\n","    inputs = self.layer4(inputs)\n","    inputs = self.layer5(inputs)\n","    inputs = self.layer6(inputs)\n","    inputs = self.layer7(inputs)\n","    inputs = self.layer8(inputs)\n","\n","    # inputs = self.upsample(inputs)\n","\n","    inputs = tf.keras.activations.tanh(inputs)\n","    return inputs"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4315,"status":"ok","timestamp":1661662421263,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"pDFdLdFPjRxE","outputId":"34a66ae4-db82-42d2-f66d-0c85aace945d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"generator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," layer0 (Sequential)         (None, 64, 64, 32)        4864      \n","                                                                 \n"," layer1 (Sequential)         (None, 32, 32, 32)        38688     \n","                                                                 \n"," layer2 (Sequential)         (None, 16, 16, 64)        132672    \n","                                                                 \n"," layer3 (Sequential)         (None, 8, 8, 128)         527488    \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," reshape (Reshape)           (None, 4, 4, 4, 128)      0         \n","                                                                 \n"," decode_block (DecodeBlock)  (None, 8, 8, 8, 64)       332416    \n","                                                                 \n"," decode_block_1 (DecodeBlock  (None, 16, 16, 16, 32)   83264     \n"," )                                                               \n","                                                                 \n"," decode_block_2 (DecodeBlock  (None, 32, 32, 32, 16)   20896     \n"," )                                                               \n","                                                                 \n"," decode_block_3 (DecodeBlock  (None, 64, 64, 64, 8)    5264      \n"," )                                                               \n","                                                                 \n"," decode_block_4 (DecodeBlock  (None, 128, 128, 128, 1)  253      \n"," )                                                               \n","                                                                 \n","=================================================================\n","Total params: 1,145,805\n","Trainable params: 1,143,017\n","Non-trainable params: 2,788\n","_________________________________________________________________\n"]}],"source":["# # Build Model\n","# # initialize model\n","model = Generator()\n","# encoder_model.build(input_shape=INPUT_SHAPE)\n","model.build(input_shape=(40, 256, 256, 3))\n","\n","# summary model\n","model.call(layers.Input((256, 256, 3)))\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"tl7Y4c_vKBGX"},"source":["## Discriminator"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1661662421264,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"EMyTKt5O1mU8"},"outputs":[],"source":["class EncodeBlockD(layers.Layer):\n","  def __init__(self, filters):\n","    super().__init__()\n","    self.conv1 = layers.Conv3D(filters=filters, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')\n","    # self.bn1 = layers.BatchNormalization()\n","    self.rl1 = layers.LeakyReLU(alpha=0.2)\n","    self.conv2 = layers.Conv3D(filters=filters, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')\n","    # self.bn2 = layers.BatchNormalization()\n","    self.rl2 = layers.LeakyReLU(alpha=0.2)\n","    self.pool = layers.MaxPool3D(pool_size=2, padding='same')\n","  def call(self, inputs):\n","    inputs = self.conv1(inputs)\n","    # inputs = self.bn1(inputs)\n","    inputs = self.rl1(inputs)\n","    inputs = self.conv2(inputs)\n","    # inputs = self.bn2(inputs)\n","    inputs = self.rl2(inputs)\n","    inputs = self.pool(inputs)\n","    return inputs"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1661662421264,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"TbImXCPgvx0q"},"outputs":[],"source":["class Discriminator(keras.Model):\n","  def __init__(self):\n","    super().__init__()\n","\n","    # self.downsample = layers.MaxPool3D(pool_size=(2, 2, 2))\n","\n","    filters_layers = [4, 16, 32, 64, 128]\n","\n","    self.layer0 = EncodeBlockD(filters_layers[0])\n","    self.do0 = layers.Dropout(0.3)\n","    self.layer1 = EncodeBlockD(filters_layers[1])\n","    self.do1 = layers.Dropout(0.3)\n","    self.layer2 = EncodeBlockD(filters_layers[2])\n","    self.do2 = layers.Dropout(0.3)\n","    self.layer3 = EncodeBlockD(filters_layers[3])\n","    self.do3 = layers.Dropout(0.3)\n","    self.layer4 = EncodeBlockD(filters_layers[4])\n","    self.do4 = layers.Dropout(0.3)\n","\n","    self.flatten = layers.Flatten()\n","    self.fc1 = layers.Dense(10)\n","    self.fc2 = layers.Dense(1)\n","    # self.softmax = layers.Softmax()\n","\n","  def call(self, inputs):\n","    # inputs = self.downsample(inputs)\n","\n","    inputs = self.layer0(inputs)\n","    inputs = self.do0(inputs)\n","    inputs = self.layer1(inputs)\n","    inputs = self.do1(inputs)\n","    inputs = self.layer2(inputs)\n","    inputs = self.do2(inputs)\n","    inputs = self.layer3(inputs)\n","    inputs = self.do3(inputs)\n","    inputs = self.layer4(inputs)\n","    inputs = self.do4(inputs)\n","    inputs = self.flatten(inputs)\n","    inputs = self.fc1(inputs)\n","    inputs = self.fc2(inputs)\n","    # inputs = self.softmax(inputs)\n","    # inputs = tf.math.sigmoid(inputs)\n","    return inputs"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":708,"status":"ok","timestamp":1661662421958,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"nCEl9PEF2O9y","outputId":"7929ba54-0d9e-4c52-9b1f-ac09a166110c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"discriminator\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," encode_block_d (EncodeBlock  (None, 128, 128, 128, 4)  548      \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 128, 128, 128, 4)  0         \n","                                                                 \n"," encode_block_d_1 (EncodeBlo  (None, 64, 64, 64, 16)   8672      \n"," ckD)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64, 64, 64, 16)    0         \n","                                                                 \n"," encode_block_d_2 (EncodeBlo  (None, 32, 32, 32, 32)   41536     \n"," ckD)                                                            \n","                                                                 \n"," dropout_2 (Dropout)         (None, 32, 32, 32, 32)    0         \n","                                                                 \n"," encode_block_d_3 (EncodeBlo  (None, 16, 16, 16, 64)   166016    \n"," ckD)                                                            \n","                                                                 \n"," dropout_3 (Dropout)         (None, 16, 16, 16, 64)    0         \n","                                                                 \n"," encode_block_d_4 (EncodeBlo  (None, 8, 8, 8, 128)     663808    \n"," ckD)                                                            \n","                                                                 \n"," dropout_4 (Dropout)         (None, 8, 8, 8, 128)      0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 65536)             0         \n","                                                                 \n"," dense (Dense)               (None, 10)                655370    \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 1,535,961\n","Trainable params: 1,535,961\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["discriminator = Discriminator()\n","discriminator.build(input_shape=(None, 256, 256, 256, 1))\n","\n","# summary model\n","discriminator.call(layers.Input((256, 256, 256, 1)))\n","discriminator.summary()"]},{"cell_type":"markdown","metadata":{"id":"WWWp-73YKDwh"},"source":["## Shape Estimator"]},{"cell_type":"markdown","metadata":{"id":"XImOu897z4wP"},"source":["### Metrics"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661662421959,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"ii192M5Qz3D8"},"outputs":[],"source":["# reference: https://stackoverflow.com/questions/61673551/working-of-the-earth-mover-loss-method-in-keras-and-input-arguments-data-types\n","def earth_mover_loss(y_true, y_pred):\n","  # cdf_true = K.cumsum(tf.cast(y_true, np.float32), axis=-1)\n","  # cdf_pred = K.cumsum(y_pred, axis=-1)\n","  # emd = K.sqrt(K.mean(K.square(cdf_true - cdf_pred), axis=-1))\n","  diff = tf.cast(y_true, np.float32) - y_pred\n","  emd = K.cumsum(diff, axis=-1)\n","  return K.abs(K.mean(emd))"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661662421959,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"REZcAOFJ2bz9"},"outputs":[],"source":["class ShapeEstimator(keras.Model):\n","  def __init__(self, generator, discriminator, gp_weight):\n","    super().__init__()\n","    self.generator = generator\n","    self.discriminator = discriminator\n","    # self.base_loss = tf.keras.losses.MeanAbsoluteError()\n","    self.base_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","    self.gp_weight = gp_weight\n","\n","  def compile(self, gen_optimizer, disc_optimizer, metric):\n","    super().compile()\n","    self.gen_optimizer = gen_optimizer\n","    self.disc_optimizer = disc_optimizer\n","    self.metric = metric\n","\n","  # loss functions\n","  # gradient penalty\n","  def gradient_penalty(self, batch_size, fake_shapes, real_shapes):\n","    \"\"\"Calculates the gradient penalty.\n","\n","    This loss is calculated on an interpolated image\n","    and added to the discriminator loss.\n","    \"\"\"\n","    # Get the interpolated image\n","    alpha = tf.random.uniform([batch_size, 1, 1, 1, 1], 0.0, 1.0)\n","    diff = fake_shapes - real_shapes\n","    # interpolated = real_shapes + alpha * diff\n","    interpolated = alpha * diff\n","\n","    with tf.GradientTape() as gp_tape:\n","      gp_tape.watch(interpolated)\n","      # 1. Get the discriminator output for this interpolated image.\n","      pred = self.discriminator(interpolated, training=True)\n","\n","    # 2. Calculate the gradients w.r.t to this interpolated image.\n","    grads = gp_tape.gradient(pred, [interpolated])[0]\n","    # 3. Calculate the norm of the gradients.\n","    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n","    gp = tf.reduce_mean((norm - 1.0) ** 2)\n","    return gp\n","\n","  # 1. WGAN\n","  def generator_loss(self, fake_output):\n","    return -tf.reduce_mean(fake_output)\n","  \n","  def discriminator_loss(self, fake_output, real_output):\n","    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n","\n","  # 2. Basic loss\n","  # def generator_loss(self, fake_output):\n","  #   return self.base_loss(tf.ones_like(fake_output), fake_output)\n","\n","  # def discriminator_loss(self, fake_output, real_output):\n","  #   real_loss = self.base_loss(tf.ones_like(real_output), real_output)\n","  #   fake_loss = self.base_loss(tf.zeros_like(fake_output), fake_output)\n","  #   total_loss = real_loss + fake_loss\n","  #   return total_loss\n","\n","  # # 3. LS GAN loss\n","  # # reference: https://github.com/pianomania/LSGAN/blob/master/model.py\n","  # def generator_loss(self, fake_output):\n","  #   return tf.reduce_mean(tf.square(fake_output-1))/2\n","\n","  # def discriminator_loss(self, fake_output, real_output):\n","  #   return tf.reduce_mean(tf.square(real_output-1) + tf.square(fake_output))/2\n","\n","  # 4. Original GAN\n","  # def generator_loss(self, fake_output):\n","  #   return tf.reduce_mean(tf.math.log(fake_output))\n","\n","  # def discriminator_loss(self, fake_output, real_output):\n","  #   return tf.reduce_mean(tf.math.log(real_output)) + tf.reduce_mean(tf.math.log(fake_output))\n","\n","  @property\n","  def metrics(self):\n","    return self.metric\n","\n","  # @tf.function\n","  # def train_step_not_skipped(self, data):\n","  #   # unpack data\n","  #   image, shape_true = data\n","  #   batch_size = tf.shape(shape_true)[0]\n","\n","  #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","  #     # predict shape with generator\n","  #     shape_pred = self.generator(image, training=True)\n","  #     # predict discrimination results with discriminator\n","  #     real_output = self.discriminator(shape_true, training=True)\n","  #     fake_output = self.discriminator(shape_pred, training=True)\n","\n","  #     # compute loss\n","  #     gen_loss = self.generator_loss(fake_output)\n","  #     disc_loss = self.discriminator_loss(fake_output, real_output)\n","\n","  #     # # compute gradient penalty\n","  #     if (self.train_counter % 1 == 0):\n","  #       gp = self.gradient_penalty(batch_size, shape_pred, tf.cast(shape_true, dtype=np.float32))\n","  #       disc_loss = disc_loss + gp * self.gp_weight\n","\n","\n","  #   # compute gradient\n","  #   gen_variables = self.generator.trainable_variables\n","  #   disc_variables = self.discriminator.trainable_variables\n","\n","  #   gen_gradients = gen_tape.gradient(gen_loss, gen_variables)\n","  #   disc_gradients = disc_tape.gradient(disc_loss, disc_variables)\n","\n","  #   # # update metrics\n","  #   metric_result = []\n","  #   # MAE\n","  #   metric_result.append(self.metric[0](shape_true, shape_pred))\n","  #   # EM\n","  #   # metric_result.append(self.metric[1](shape_true, shape_pred))\n","  #   metric_result.append(0)\n","\n","  #   # update weights\n","  #   # if (self.train_counter % 2 == 0) or (float(metric_result) > 0.25):\n","  #   if (self.train_counter % 1 == 0):\n","  #     self.disc_optimizer.apply_gradients(zip(disc_gradients, disc_variables))\n","  #   self.gen_optimizer.apply_gradients(zip(gen_gradients, gen_variables))\n","\n","  #   # update train counter\n","  #   self.train_counter += 1\n","\n","  #   return gen_loss, disc_loss, gp, shape_pred, metric_result\n","\n","\n","  @tf.function\n","  def train_step_not_skipped(self, data):\n","    # unpack data\n","    image, shape_true = data\n","    batch_size = tf.shape(shape_true)[0]\n","\n","    with tf.GradientTape() as disc_tape:\n","      # predict shape with generator\n","      shape_pred = self.generator(image, training=True)\n","      # predict discrimination results with discriminator\n","      real_output = self.discriminator(shape_true, training=True)\n","      fake_output = self.discriminator(shape_pred, training=True)\n","\n","      # compute loss\n","      # gen_loss = self.generator_loss(fake_output)\n","      disc_loss = self.discriminator_loss(fake_output, real_output)\n","\n","      # compute gradient penalty\n","      if (float(disc_loss) > 1000) or (float(disc_loss) < -1000):\n","        modified_gp_weight = 200.0\n","      else:\n","        modified_gp_weight = self.gp_weight\n","      gp = self.gradient_penalty(batch_size, shape_pred, tf.cast(shape_true, dtype=np.float32))\n","      disc_loss = disc_loss + gp * modified_gp_weight\n","\n","\n","    # compute gradient\n","    disc_variables = self.discriminator.trainable_variables\n","    disc_gradients = disc_tape.gradient(disc_loss, disc_variables)\n","\n","    # update weights\n","    self.disc_optimizer.apply_gradients(zip(disc_gradients, disc_variables))\n","\n","    with tf.GradientTape() as gen_tape:\n","      # predict shape with generator\n","      shape_pred = self.generator(image, training=True)\n","\n","      # predict discrimination results with discriminator\n","      fake_output = self.discriminator(shape_pred, training=True)\n","\n","      # compute loss\n","      gen_loss = self.generator_loss(fake_output)\n","\n","    # compute gradient\n","    gen_variables = self.generator.trainable_variables\n","    gen_gradients = gen_tape.gradient(gen_loss, gen_variables)\n","\n","    # update gradient\n","    self.gen_optimizer.apply_gradients(zip(gen_gradients, gen_variables))\n","\n","    # # update metrics\n","    metric_result = []\n","    # MAE\n","    metric_result.append(self.metric[0](shape_true, shape_pred))\n","    # EM\n","    # metric_result.append(self.metric[1](shape_true, shape_pred))\n","    metric_result.append(0)\n","\n","    return gen_loss, disc_loss, gp * modified_gp_weight, shape_pred, metric_result\n","\n","  @tf.function\n","  def test_step(self, data):\n","    # unpack data\n","    image, shape_true = data\n","\n","    # predict\n","    shape_pred = self.generator(image, training=True)\n","\n","    # update metrics\n","    metric_result = []\n","    metric_result.append(self.metric[0](shape_true, shape_pred))\n","    metric_result.append(self.metric[1](shape_true, shape_pred))\n","\n","    return metric_result, shape_pred"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1661662421960,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"DHqxPd7A9HCp"},"outputs":[],"source":["from keras.utils.generic_utils import get_custom_objects\n","def rmse(y_true, y_pred):\n","  \"\"\"\n","  Root Mean Squared Error\n","  Args:\n","      y_true ([np.array]): test samples\n","      y_pred ([np.array]): predicted samples\n","  Returns:\n","      [float]: root mean squared error\n","  \"\"\"\n","  return tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(y_true, y_pred))))\n","  # return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n","get_custom_objects().update({\"rmse\": rmse})"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":14802,"status":"ok","timestamp":1661662436757,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"4EGFx7GR2PS5"},"outputs":[],"source":["if OPTIMIZER == 'RMSprop':\n","  gen_optimizer = tf.keras.optimizers.RMSprop()\n","  disc_optimizer = tf.keras.optimizers.RMSprop()\n","else:\n","  gen_optimizer = tf.keras.optimizers.Adam(GEN_LR)\n","  disc_optimizer = tf.keras.optimizers.Adam(DISC_LR)\n","generator = Generator()\n","discriminator = Discriminator()\n","sketch_estimator = load_model('/content/gdrive/MyDrive/master/2.5D_sketches_estimator/intermediate/sketch_estimator_normal/model')\n","sketch_estimator_depth = load_model('/content/gdrive/MyDrive/master/2.5D_sketches_estimator/intermediate/sketch_estimator_depth/model')\n","\n","model = ShapeEstimator(generator=generator, discriminator=discriminator, gp_weight=GP_WEIGHT)\n","model.compile(gen_optimizer=gen_optimizer, disc_optimizer=disc_optimizer, metric=[tf.keras.metrics.RootMeanSquaredError(), earth_mover_loss])"]},{"cell_type":"markdown","metadata":{"id":"d44kQtqR2AXu"},"source":["# Fit Model"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1661662436758,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"3umdZyw82CZs"},"outputs":[],"source":["# checkpoints\n","# additional checkpoint load code and temp directory definition\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","\n","gen_checkpoint_path = project_path+\"/intermediate/shape_estimator/gen_weights{epoch:02d}.ckpt\"\n","disc_checkpoint_path = project_path+\"/intermediate/shape_estimator/disc_weights{epoch:02d}.ckpt\"\n","checkpoint_dir = os.path.dirname(gen_checkpoint_path)\n","\n","gen_checkpoint = ModelCheckpoint(filepath=gen_checkpoint_path, verbose=1)\n","disc_checkpoint = ModelCheckpoint(filepath=disc_checkpoint_path, verbose=1)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1661662436758,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"V23WLg9kgYGP"},"outputs":[],"source":["history = {'gen_loss':[],\n","      'disc_loss':[],\n","      'gen_loss_val':[],\n","      'disc_loss_val':[],\n","      'gradient_penalty':[],\n","      'metric_MAE':[],\n","      'metric_MAE_val':[],\n","      'metric_EM':[]}"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1661662436758,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"aQ5d65an2LrO"},"outputs":[],"source":["\n","# train\n","if RUN_MODE == 'train':\n","  try:\n","    with open(OUTPUT_PATH+'curr_epoch.txt', 'r') as f:\n","      curr_epoch = int(f.read())\n","      print(curr_epoch)\n","    f.close()\n","  except FileNotFoundError:\n","    curr_epoch = 0\n","    print('File not found, current epoch set as 0.')\n","\n","  if curr_epoch != 0:\n","    # loaded_generator = tf.saved_model.load(OUTPUT_PATH+'gen_weights')\n","    # loaded_discriminator = tf.saved_model.load(OUTPUT_PATH+'disc_weights')\n","    generator.load_weights(OUTPUT_PATH+'gen_weights%02d.ckpt' % curr_epoch)\n","    discriminator.load_weights(OUTPUT_PATH+'disc_weights%02d.ckpt' % curr_epoch)\n","    loaded_generator = generator\n","    loaded_discriminator = discriminator\n","    \n","    loaded_model = ShapeEstimator(generator=loaded_generator, discriminator=loaded_discriminator, gp_weight=GP_WEIGHT)\n","    loaded_model.compile(gen_optimizer=gen_optimizer, disc_optimizer=disc_optimizer, metric=[tf.keras.metrics.RootMeanSquaredError(), earth_mover_loss])\n","\n","    model = loaded_model\n","    print('Model loaded at epoch' + str(curr_epoch))\n","\n","  import time\n","  for epoch in range(curr_epoch+1, N_EPOCH):\n","    start = time.time()\n","    print('Epoch %02d' % epoch)\n","\n","\n","    # train batches\n","    prev_disc_loss = 1\n","    for step, batch in enumerate(train_loader):\n","      # # predict sketches\n","      # if PREDICT_SKETCH == True:\n","      #   batch = list(batch)\n","      #   batch[0] = sketch_estimator.predict(batch[0])\n","      #   batch = tuple(batch)\n","\n","      # concatenate sketches\n","      concatenated = np.concatenate((batch[0], batch[1]), axis=3)\n","      batch = (concatenated, batch[2])\n","\n","      # train step\n","      gen_loss, disc_loss, gp, shape_pred, metric = model.train_step_not_skipped(batch)\n","\n","      # record previous discriminator loss\n","      prev_disc_loss = float(disc_loss)\n","\n","      # log\n","      if step % 50 == 0:\n","        print('Generator loss at step %d/%d: %.2f' % (step, train_loader.__len__(), gen_loss))\n","        print('Discriminator loss at step %d/%d: %.2f' % (step, train_loader.__len__(), disc_loss))\n","        print('Gradient penalty at step %d/%d: %.2f' % (step, train_loader.__len__(), gp))\n","        print('Metric MAE at step %d/%d: %.2f' % (step, train_loader.__len__(), metric[0]))\n","        print('Metric EM at step %d/%d: %.2f' % (step, train_loader.__len__(), metric[1]))\n","\n","        # save history\n","        history['gen_loss'].append(float(gen_loss))\n","        history['disc_loss'].append(float(disc_loss))\n","        history['gradient_penalty'].append(float(gp))\n","        history['metric_MAE'].append(float(metric[0]))\n","        history['metric_EM'].append(float(metric[1]))\n","    \n","    # validation\n","    metric_hist = []\n","    for step, batch in enumerate(validation_loader):\n","      # # predict sketches\n","      # if PREDICT_SKETCH == True:\n","      #   batch = list(batch)\n","      #   batch[0] = sketch_estimator.predict(batch[0])\n","      #   batch = tuple(batch)\n","\n","      # concatenate sketches\n","      concatenated = np.concatenate((batch[0], batch[1]), axis=3)\n","      batch = (concatenated, batch[2])\n","\n","      # validate\n","      metric, shape_pred = model.test_step(batch)\n","      metric_hist.append(metric)\n","\n","      # save shapes\n","      if step % 50 == 0:\n","        try:\n","          os.makedirs(OUTPUT_PATH+'predicted_shapes_validation%02d' % epoch)\n","        except FileExistsError:\n","          pass\n","        with open(OUTPUT_PATH+'predicted_shapes_validation%02d/predicted_shape%02d.npz' % (epoch, step), 'wb+') as f:\n","          np.save(f, shape_pred)\n","        f.close()\n","        with open(OUTPUT_PATH+'predicted_shapes_validation%02d/real_shape%02d.npz' % (epoch, step), 'wb+') as f:\n","          np.save(f, batch[1])\n","        f.close()\n","\n","    # show validation results\n","    validation_metric_MAE = sum(metric_hist[0]) / len(metric_hist[0])\n","    print('Validation metric MAE: %.2f' % validation_metric_MAE)\n","    # validation_metric_EM = sum(metric_hist[1]) / len(metric_hist[1])\n","    # print('Validation metric EM: %.2f' % validation_metric_EM)\n","\n","    # save validation results\n","    history['gen_loss_val'].append(float(gen_loss))\n","    history['disc_loss_val'].append(float(disc_loss))\n","    history['metric_MAE_val'].append(float(validation_metric_MAE))\n","\n","    # save models\n","    # model.generator.save(OUTPUT_PATH+'gen_weights%02d.ckpt' % epoch)\n","    # model.discriminator.save(OUTPUT_PATH+'disc_weights%02d.ckpt' % epoch)\n","    model.generator.save_weights(OUTPUT_PATH+'gen_weights%02d.ckpt' % epoch)\n","    model.discriminator.save_weights(OUTPUT_PATH+'disc_weights%02d.ckpt' % epoch)\n","\n","    # save sample predicted shapes and real shapes\n","    try:\n","      os.makedirs(OUTPUT_PATH+'predicted_shapes')\n","    except FileExistsError:\n","      pass\n","    with open(OUTPUT_PATH+'predicted_shapes/predicted_shape%02d.npz' % epoch, 'wb+') as f:\n","      np.save(f, shape_pred)\n","    f.close()\n","    with open(OUTPUT_PATH+'predicted_shapes/real_shape%02d.npz' % epoch, 'wb+') as f:\n","      np.save(f, batch[1])\n","    f.close()\n","    print('Shape saved at epoch %02d' % epoch)\n","\n","    # save checkpoint\n","    with open(OUTPUT_PATH+'curr_epoch.txt', 'w') as f:\n","      f.write(str(epoch))\n","    f.close()\n","\n","    print('Passed time: '+str(time.time()-start))"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1661662436759,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"sz9yK5txhGg4"},"outputs":[],"source":["if RUN_MODE == 'train':\n","  # save model history\n","  with open(OUTPUT_PATH+'history.json', 'w+') as f:\n","    json.dump(dict(history), f)\n","  f.close()\n","\n","  # save models\n","  generator.save_weights(OUTPUT_PATH+'gen_weights')\n","  discriminator.save_weights(OUTPUT_PATH+'disc_weights')"]},{"cell_type":"markdown","metadata":{"id":"b05aS76fajvo"},"source":["# Demonstrate Results"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1661662436759,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"t3sP9PZXiND5"},"outputs":[],"source":["# if RUN_MODE == 'test':\n","#   metric_hist = []\n","\n","#   # load model\n","#   loaded_generator = tf.saved_model.load(OUTPUT_PATH+'gen_weights03.ckpt')\n","#   loaded_discriminator = tf.saved_model.load(OUTPUT_PATH+'disc_weights03.ckpt')\n","#   # loaded_generator = tf.keras.models.load_model(OUTPUT_PATH+'gen_weights')\n","#   # loaded_discriminator = tf.keras.models.load_model(OUTPUT_PATH+'disc_weights')\n","# generator.load_weights(OUTPUT_PATH+'gen_weights%02d.ckpt' % curr_epoch)\n","# discriminator.load_weights(OUTPUT_PATH+'disc_weights%02d.ckpt' % curr_epoch)\n","# loaded_generator = generator\n","# loaded_discriminator = discriminator\n","  \n","#   loaded_model = ShapeEstimator(generator=loaded_generator, discriminator=loaded_discriminator, gp_weight=GP_WEIGHT)\n","#   loaded_model.compile(gen_optimizer=gen_optimizer, disc_optimizer=disc_optimizer, metric=[tf.keras.losses.MeanAbsoluteError(), earth_mover_loss])\n","\n","#   # test batches\n","#   for step, batch in enumerate(test_loader):\n","#     # predict sketches\n","#     # batch = list(batch)\n","#     # batch[0] = sketch_estimator.predict(batch[0])\n","#     # batch = tuple(batch)\n","#     metric, shape_pred = loaded_model.test_step(batch)\n","#     metric_hist.append(metric)\n","\n","#     # save sample predicted shapes and real shapes\n","#     if step % 1 == 0:\n","#       try:\n","#         os.makedirs(OUTPUT_PATH+'predicted_shapes_test')\n","#       except FileExistsError:\n","#         pass\n","#       with open(OUTPUT_PATH+'predicted_shapes_test/predicted_shape%02d.npz' % step, 'wb+') as f:\n","#         np.save(f, shape_pred)\n","#       f.close()\n","#       with open(OUTPUT_PATH+'predicted_shapes_test/real_shape%02d.npz' % step, 'wb+') as f:\n","#         np.save(f, batch[1])\n","#       f.close()\n","#       with open(OUTPUT_PATH+'predicted_shapes_test/image%02d.npz' % step, 'wb+') as f:\n","#         np.save(f, batch[0])\n","#       f.close()\n","#       print('Shape saved at step %02d' % step)\n","#   avg_metric_MAE = sum(metric_hist[0]) / len(metric_hist[0])\n","#   avg_metric_EM = sum(metric_hist[1]) / len(metric_hist[1])\n","#   print('Average metric MAE: ' + str(avg_metric_MAE))\n","#   print('Average metric EM: ' + str(avg_metric_EM))"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169083,"status":"ok","timestamp":1661662607079,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"8iP0WEryNG0A","outputId":"9831ebdb-4291-46ab-f44c-e11cc1189763"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape saved at step 00\n","Shape saved at step 10\n","Shape saved at step 20\n","Shape saved at step 30\n","Shape saved at step 40\n","Shape saved at step 50\n","Shape saved at step 60\n","Shape saved at step 70\n","Shape saved at step 80\n","Shape saved at step 90\n","Shape saved at step 100\n","Shape saved at step 110\n","Shape saved at step 120\n","Shape saved at step 130\n","Shape saved at step 140\n","Shape saved at step 150\n","Shape saved at step 160\n","Shape saved at step 170\n","Average metric MAE: tf.Tensor(0.22355634, shape=(), dtype=float32)\n","Average metric EM: tf.Tensor(0.19753934, shape=(), dtype=float32)\n"]}],"source":["metric_hist = []\n","\n","# # load model\n","# loaded_generator = tf.saved_model.load(OUTPUT_PATH+'gen_weights03.ckpt')\n","# loaded_discriminator = tf.saved_model.load(OUTPUT_PATH+'disc_weights03.ckpt')\n","# # loaded_generator = tf.keras.models.load_model(OUTPUT_PATH+'gen_weights')\n","# # loaded_discriminator = tf.keras.models.load_model(OUTPUT_PATH+'disc_weights')\n","curr_epoch = 10\n","generator.load_weights(OUTPUT_PATH+'gen_weights%02d.ckpt' % curr_epoch)\n","discriminator.load_weights(OUTPUT_PATH+'disc_weights%02d.ckpt' % curr_epoch)\n","loaded_generator = generator\n","loaded_discriminator = discriminator\n","\n","loaded_model = ShapeEstimator(generator=loaded_generator, discriminator=loaded_discriminator, gp_weight=GP_WEIGHT)\n","loaded_model.compile(gen_optimizer=gen_optimizer, disc_optimizer=disc_optimizer, metric=[tf.keras.metrics.RootMeanSquaredError(), earth_mover_loss])\n","\n","# loaded_model = model\n","\n","# test batches\n","count = 0\n","for step, batch in enumerate(test_loader):\n","  # save original image\n","  if step % 10 == 0:\n","    try:\n","      os.makedirs(OUTPUT_PATH+'predicted_shapes_test')\n","    except FileExistsError:\n","      pass\n","    with open(OUTPUT_PATH+'predicted_shapes_test/real_raw_image%02d.npz' % count, 'wb+') as f:\n","      np.save(f, batch[3])\n","    f.close()\n","    with open(OUTPUT_PATH+'predicted_shapes_test/real_normal_image%02d.npz' % count, 'wb+') as f:\n","      np.save(f, batch[0])\n","    f.close()\n","    with open(OUTPUT_PATH+'predicted_shapes_test/real_depth_image%02d.npz' % count, 'wb+') as f:\n","      np.save(f, batch[1])\n","    f.close()\n","    with open(OUTPUT_PATH+'predicted_shapes_test/predicted_normal_image%02d.npz' % count, 'wb+') as f:\n","      np.save(f, sketch_estimator.predict(batch[3]))\n","    f.close()\n","    with open(OUTPUT_PATH+'predicted_shapes_test/predicted_depth_image%02d.npz' % count, 'wb+') as f:\n","      np.save(f, sketch_estimator_depth.predict(batch[3]))\n","    f.close()\n","\n","  # predict sketches\n","  # batch = list(batch)\n","  # batch[0] = sketch_estimator.predict(batch[0])\n","  # batch = tuple(batch)\n","\n","  # concatenate sketches\n","  concatenated = np.concatenate((batch[0], batch[1]), axis=3)\n","  # concatenated = np.concatenate((sketch_estimator.predict(batch[3]), sketch_estimator_depth.predict(batch[3])), axis=3)\n","  batch = (concatenated, batch[2])\n","\n","  metric, shape_pred = loaded_model.test_step(batch)\n","  metric_hist.append(metric)\n","\n","  # save sample predicted shapes and real shapes\n","  if step % 10 == 0:\n","    try:\n","      os.makedirs(OUTPUT_PATH+'predicted_shapes_test')\n","    except FileExistsError:\n","      pass\n","    with open(OUTPUT_PATH+'predicted_shapes_test/predicted_shape%02d.npz' % count, 'wb+') as f:\n","      np.save(f, shape_pred)\n","    f.close()\n","    with open(OUTPUT_PATH+'predicted_shapes_test/real_shape%02d.npz' % count, 'wb+') as f:\n","      np.save(f, batch[1])\n","    f.close()\n","    # with open(OUTPUT_PATH+'predicted_shapes_test/predicted_image%02d.npz' % count, 'wb+') as f:\n","    #   np.save(f, batch[0])\n","    # f.close()\n","    print('Shape saved at step %02d' % step)\n","    count += 1\n","avg_metric_MAE = sum(metric_hist[0]) / len(metric_hist[0])\n","avg_metric_EM = sum(metric_hist[1]) / len(metric_hist[1])\n","print('Average metric MAE: ' + str(avg_metric_MAE))\n","print('Average metric EM: ' + str(avg_metric_EM))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":683},"executionInfo":{"elapsed":1546,"status":"ok","timestamp":1661662608611,"user":{"displayName":"Zhangli Wang","userId":"16506856843900060570"},"user_tz":-60},"id":"qbXtROtxVsZr","outputId":"a4c0dc03-135e-485d-b791-54a01346cdde"},"outputs":[],"source":["# list all data in history\n","with open(OUTPUT_PATH+'history.json', 'r') as f:\n","  history = json.load(f)\n","f.close()\n","# summarize history for accuracy\n","plt.figure(figsize=(8,5))\n","plt.plot(history['gen_loss'])\n","plt.plot(history['disc_loss'])\n","plt.title('Loss History of Net')\n","plt.ylabel('loss')\n","plt.xlabel('time')\n","plt.xticks(np.arange(0, len(history['gen_loss']), 100.0))\n","# plt.yticks(np.arange(0.0, max(max(history['disc_loss']), max(history['gen_loss'])), 1.0))\n","plt.ylim(-1000, 1000)\n","plt.legend(['gen', 'disc'], loc='upper left')\n","plt.savefig(OUTPUT_PATH+'losses.jpg')\n","plt.show()\n","# summarize history for metric\n","plt.figure(figsize=(8,5))\n","plt.plot(history['metric_MAE'])\n","plt.title('Metric History of Net')\n","plt.ylabel('metric')\n","plt.xlabel('epoch')\n","plt.xticks(np.arange(0, len(history['gen_loss']), 100.0))\n","plt.yticks(np.arange(0.0, 0.5, 0.1))\n","plt.ylim(0.0, 0.5)\n","plt.legend(['metric'], loc='upper left')\n","plt.savefig(OUTPUT_PATH+'metrics.jpg')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"3D Shapes Estimator - Normal Feasible Adam.ipynb","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
